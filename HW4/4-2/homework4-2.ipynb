{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","toc_visible":true,"authorship_tag":"ABX9TyPBFxaEgiLS4FopMGjhDai9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"94hfWdaztud3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_-v6vDztQKM"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# read files from google drive\n","import os\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","\n","# import modules from google drive\n","import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)"],"metadata":{"id":"gYdzoUSDtjWZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658838083403,"user_tz":-480,"elapsed":22849,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"9827790d-6bbd-4f3d-d4e0-c3ac1171f0df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","['scripts', 'structural-probes', 'example', 'homework4-2.ipynb']\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FkI3yVgSc7dS","executionInfo":{"status":"ok","timestamp":1658838092519,"user_tz":-480,"elapsed":9131,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"50557bf4-3af9-48d6-9915-cb634d8bb219"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 5.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 14.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 74.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 83.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"]}]},{"cell_type":"code","source":["!pip install mafan"],"metadata":{"id":"juKNR4Hge1ge","colab":{"base_uri":"https://localhost:8080/","height":877},"executionInfo":{"status":"ok","timestamp":1658848255773,"user_tz":-480,"elapsed":12884,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"8bba84cf-0bb4-4ab2-cc01-92e0ab3faa66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mafan\n","  Downloading mafan-0.3.1.tar.gz (70 kB)\n","\u001b[K     |████████████████████████████████| 70 kB 3.5 MB/s \n","\u001b[?25hCollecting jieba==0.37\n","  Downloading jieba-0.37.zip (6.4 MB)\n","\u001b[K     |████████████████████████████████| 6.4 MB 10.8 MB/s \n","\u001b[?25hCollecting argparse==1.1\n","  Downloading argparse-1.1.zip (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 55.1 MB/s \n","\u001b[?25hCollecting chardet==2.1.1\n","  Downloading chardet-2.1.1.tar.gz (178 kB)\n","\u001b[K     |████████████████████████████████| 178 kB 57.5 MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mafan) (0.16.0)\n","Building wheels for collected packages: mafan, argparse, chardet, jieba\n","  Building wheel for mafan (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mafan: filename=mafan-0.3.1-py3-none-any.whl size=66441 sha256=06b8a9e02fd434f99857a76dd88634452781a6be75d669f2775713375d171d99\n","  Stored in directory: /root/.cache/pip/wheels/8f/c3/76/dad6186c6a841b0996bc4bbe1015fd4c19cc2acbb3328742d6\n","  Building wheel for argparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for argparse: filename=argparse-1.1-py3-none-any.whl size=20735 sha256=d651a97335627cd374bd9e825e275d92ef0fc7ab62d71c5df8c7b065f6b1eee0\n","  Stored in directory: /root/.cache/pip/wheels/59/e1/77/ca719b6be5cfdef5d09090cb37f86df1d9bbdd0749a0e48860\n","  Building wheel for chardet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for chardet: filename=chardet-2.1.1-py3-none-any.whl size=185382 sha256=4beee206b9438ac3e8d83cac5f05441b2a401f0be1400cd031a3ccb8c80a66d9\n","  Stored in directory: /root/.cache/pip/wheels/ca/4c/e4/3b0317a6a0ac0ff662e81aa0eeb55339553eb53f00fc4f79d4\n","  Building wheel for jieba (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jieba: filename=jieba-0.37-py3-none-any.whl size=6369291 sha256=54e3cce45a6a6ed66abbe4d50e3c5345a97cf7c3dcb3cb66cabf8e00d8757929\n","  Stored in directory: /root/.cache/pip/wheels/74/33/3a/2484a150a83810a335be80c2ca6751e8951886af4e8a46a565\n","Successfully built mafan argparse chardet jieba\n","Installing collected packages: jieba, chardet, argparse, mafan\n","  Attempting uninstall: jieba\n","    Found existing installation: jieba 0.42.1\n","    Uninstalling jieba-0.42.1:\n","      Successfully uninstalled jieba-0.42.1\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 3.0.4\n","    Uninstalling chardet-3.0.4:\n","      Successfully uninstalled chardet-3.0.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires chardet<4,>=3.0.2, but you have chardet 2.1.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed argparse-1.1 chardet-2.1.1 jieba-0.37 mafan-0.3.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]}}},"metadata":{}}]},{"cell_type":"code","source":["# %cd $GOOGLE_DRIVE_PATH"],"metadata":{"id":"HMZIcfXLtj00"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 1. Download repository "],"metadata":{"id":"Zw9pzeuwpWdQ"}},{"cell_type":"markdown","source":["Clone the repository below:\n","\n","`git clone https://github.com/Sologa/structural-probes.git`"],"metadata":{"id":"4rSEic8KpeFl"}},{"cell_type":"markdown","source":["# Step 2. Download dataset"],"metadata":{"id":"oycHCI-T4oZq"}},{"cell_type":"markdown","source":["Download dataset and put it under `data/ctb`.\n","\n"],"metadata":{"id":"8VdpAANDpsRI"}},{"cell_type":"code","source":["!mkdir ctb\n","%cd ctb"],"metadata":{"id":"vbWy3u4L4rGK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658838111894,"user_tz":-480,"elapsed":296,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"47bbbcac-76bd-4d48-8485-898b06478d44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ctb\n"]}]},{"cell_type":"code","source":["# train\n","!gdown https://drive.google.com/uc?id=1lVshlLaDqiXzFTa_2YVCYEgNDhjkF9Zr\n","\n","# dev\n","!gdown https://drive.google.com/uc?id=1w6vPMb6qjMyeoyZftIf3-dIHqsEIjWvs\n","\n","# test\n","!gdown https://drive.google.com/uc?id=1di070sukuP8JQqPTq0zm_qe6PXgPKYCm\n","\n","%cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wm6csY_uVqhi","executionInfo":{"status":"ok","timestamp":1658838119039,"user_tz":-480,"elapsed":5336,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"8577f2ba-72db-4c06-cdbe-55baf6084a19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1lVshlLaDqiXzFTa_2YVCYEgNDhjkF9Zr\n","To: /content/ctb/train.conllx\n","100% 12.7M/12.7M [00:00<00:00, 77.0MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1w6vPMb6qjMyeoyZftIf3-dIHqsEIjWvs\n","To: /content/ctb/dev.conllx\n","100% 621k/621k [00:00<00:00, 142MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1di070sukuP8JQqPTq0zm_qe6PXgPKYCm\n","To: /content/ctb/test.conllx\n","100% 1.53M/1.53M [00:00<00:00, 199MB/s]\n","/content\n"]}]},{"cell_type":"code","source":["%cd $GOOGLE_DRIVE_PATH"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_n1r0kcpWucT","executionInfo":{"status":"ok","timestamp":1658838132757,"user_tz":-480,"elapsed":301,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"e785b3ea-de79-41c5-d091-93de4d5f9870"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2\n"]}]},{"cell_type":"markdown","source":["# Step 3. Preprocessing\n"],"metadata":{"id":"-PMdJsI642TT"}},{"cell_type":"code","source":["!bash ./scripts/gen_ctb.sh"],"metadata":{"id":"t1qsblg644bO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658838479976,"user_tz":-480,"elapsed":297612,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"d2cde938-3af2-4ca0-c7ac-ac241ca8bdef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: 100% 107k/107k [00:00<00:00, 1.93MB/s]\n","Downloading: 100% 29.0/29.0 [00:00<00:00, 42.2kB/s]\n","Downloading: 100% 624/624 [00:00<00:00, 883kB/s]\n","Downloading: 100% 393M/393M [00:06<00:00, 65.2MB/s]\n","Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","15346it [03:44, 68.39it/s]\n","Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","803it [00:11, 72.07it/s]\n","Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","1905it [00:25, 73.44it/s]\n"]}]},{"cell_type":"markdown","source":["# Step 4. Training"],"metadata":{"id":"rSfV2KmT45gB"}},{"cell_type":"code","source":["# executing for about 2.1 hr\n","!bash ./scripts/call_exp.sh"],"metadata":{"id":"MyiyqZ4x47Zj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658846317142,"user_tz":-480,"elapsed":7566950,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"02bfa1e5-40f1-4c5b-a597-6fc61e74f678"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Constructing new results directory at results/parse-distance-0\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 0\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [01:24<00:00, 181.47it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 0\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 380.81it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 0\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:05<00:00, 369.79it/s]\n","[computing labels]: 100% 15346/15346 [03:33<00:00, 71.81it/s]\n","[computing labels]: 100% 803/803 [00:09<00:00, 81.75it/s]\n","[computing labels]: 100% 1905/1905 [00:23<00:00, 79.60it/s] \n","Constructing TwoWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.6877818956192416, Dev loss: 1.1836699810004323\n","Saving probe parameters\n","[epoch 1] Train loss: 1.2692124663688176, Dev loss: 1.218282063010324\n","[epoch 2] Train loss: 1.0213357572929653, Dev loss: 1.0090714350138625\n","Saving probe parameters\n","[epoch 3] Train loss: 0.9980200995961426, Dev loss: 1.0078694339410157\n","Saving probe parameters\n","[epoch 4] Train loss: 0.992311216746131, Dev loss: 1.0097656748808483\n","[epoch 5] Train loss: 0.9705685689243301, Dev loss: 0.9916488494849294\n","Saving probe parameters\n","[epoch 6] Train loss: 0.9660976801238004, Dev loss: 0.9917220344875997\n","[epoch 7] Train loss: 0.9624739133222588, Dev loss: 0.990339371810666\n","Saving probe parameters\n","[epoch 8] Train loss: 0.9619589511906637, Dev loss: 0.9901569973338734\n","Saving probe parameters\n","[epoch 9] Train loss: 0.9617394735430018, Dev loss: 0.9900317741360789\n","Saving probe parameters\n","[epoch 10] Train loss: 0.961551116713175, Dev loss: 0.9899214979720442\n","Saving probe parameters\n","[epoch 11] Train loss: 0.961394208111136, Dev loss: 0.9899891429345308\n","[epoch 12] Train loss: 0.9609777931438095, Dev loss: 0.9898621578739114\n","[epoch 13] Train loss: 0.9609157695121472, Dev loss: 0.9898539212988144\n","[epoch 14] Train loss: 0.9609128412485092, Dev loss: 0.989850945371768\n","[epoch 15] Train loss: 0.9609101615019825, Dev loss: 0.9898474623227624\n","Early stopping\n","[training]:  50% 15/30 [01:41<01:41,  6.80s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 486.67it/s]\n","Reporting spearmanr on split dev\n","Reporting uuas on split dev\n","[uuas,tikz]: 81it [00:22,  3.57it/s]\n","Constructing new results directory at results/parse-depth-0\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 0\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:44<00:00, 343.32it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 0\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 378.22it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 0\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:05<00:00, 367.12it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2625.94it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2894.74it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2775.07it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.3336664201320576, Dev loss: 1.0245097535633358\n","Saving probe parameters\n","[epoch 1] Train loss: 1.0447086675154966, Dev loss: 1.0959972878025002\n","[epoch 2] Train loss: 0.8423192196558527, Dev loss: 0.8494764003777415\n","Saving probe parameters\n","[epoch 3] Train loss: 0.8185086795315195, Dev loss: 0.844008397046537\n","Saving probe parameters\n","[epoch 4] Train loss: 0.8131174102812039, Dev loss: 0.8422172506006984\n","Saving probe parameters\n","[epoch 5] Train loss: 0.8089997243899869, Dev loss: 0.8454194704295689\n","[epoch 6] Train loss: 0.785812405521985, Dev loss: 0.8262896852505163\n","Saving probe parameters\n","[epoch 7] Train loss: 0.7806944736799889, Dev loss: 0.8244383189627718\n","Saving probe parameters\n","[epoch 8] Train loss: 0.7790186512070965, Dev loss: 0.8247082450173118\n","[epoch 9] Train loss: 0.7755673861979009, Dev loss: 0.8232060500129519\n","Saving probe parameters\n","[epoch 10] Train loss: 0.775116686993125, Dev loss: 0.8230239706645125\n","Saving probe parameters\n","[epoch 11] Train loss: 0.7749131376982885, Dev loss: 0.8229254548012246\n","[epoch 12] Train loss: 0.7747443453765018, Dev loss: 0.8228968332891595\n","Saving probe parameters\n","[epoch 13] Train loss: 0.7743275445364887, Dev loss: 0.8227811717749532\n","Saving probe parameters\n","[epoch 14] Train loss: 0.7742874367861957, Dev loss: 0.822762608973502\n","[epoch 15] Train loss: 0.7742369817534652, Dev loss: 0.8227539216893103\n","[epoch 16] Train loss: 0.7742326586339398, Dev loss: 0.8227519294244712\n","[epoch 17] Train loss: 0.7742298950540589, Dev loss: 0.822751040179584\n","[epoch 18] Train loss: 0.7742274194998551, Dev loss: 0.8227497299165832\n","Early stopping\n","[training]:  60% 18/30 [01:22<00:54,  4.58s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 627.48it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-distance-1\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 1\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:53<00:00, 285.55it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 1\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 372.46it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 1\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:05<00:00, 361.61it/s]\n","[computing labels]: 100% 15346/15346 [03:32<00:00, 72.25it/s]\n","[computing labels]: 100% 803/803 [00:09<00:00, 82.25it/s]\n","[computing labels]: 100% 1905/1905 [00:23<00:00, 80.06it/s]\n","Constructing TwoWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.879116668207742, Dev loss: 1.158696171652484\n","Saving probe parameters\n","[epoch 1] Train loss: 1.3539128603687285, Dev loss: 1.2794380440361621\n","[epoch 2] Train loss: 0.980222412524751, Dev loss: 0.9731457254212642\n","Saving probe parameters\n","[epoch 3] Train loss: 0.9565090149675993, Dev loss: 0.965178460587897\n","Saving probe parameters\n","[epoch 4] Train loss: 0.9513966283384333, Dev loss: 0.9593108582170042\n","Saving probe parameters\n","[epoch 5] Train loss: 0.9482496899637486, Dev loss: 0.9627630550270508\n","[epoch 6] Train loss: 0.9250323536280126, Dev loss: 0.9452099319115967\n","Saving probe parameters\n","[epoch 7] Train loss: 0.9198867597931696, Dev loss: 0.9439993721165069\n","Saving probe parameters\n","[epoch 8] Train loss: 0.9183369512494596, Dev loss: 0.944118108428727\n","[epoch 9] Train loss: 0.9147218318055759, Dev loss: 0.9428825990052182\n","Saving probe parameters\n","[epoch 10] Train loss: 0.91431493468939, Dev loss: 0.9427029216571584\n","Saving probe parameters\n","[epoch 11] Train loss: 0.9141287776306184, Dev loss: 0.9427824863609608\n","[epoch 12] Train loss: 0.9136439978990937, Dev loss: 0.9425957318706204\n","Saving probe parameters\n","[epoch 13] Train loss: 0.9136171564974438, Dev loss: 0.9425725485586735\n","[epoch 14] Train loss: 0.9135633093211109, Dev loss: 0.9425652193399622\n","[epoch 15] Train loss: 0.9135610921805799, Dev loss: 0.9425630174567958\n","[epoch 16] Train loss: 0.9135591950858415, Dev loss: 0.9425609295869972\n","[epoch 17] Train loss: 0.9135573635849542, Dev loss: 0.9425584120887006\n","Early stopping\n","[training]:  57% 17/30 [01:55<01:28,  6.79s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 479.73it/s]\n","Reporting spearmanr on split dev\n","Reporting uuas on split dev\n","[uuas,tikz]: 81it [00:22,  3.60it/s]\n","Constructing new results directory at results/parse-depth-1\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 1\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:43<00:00, 353.62it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 1\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:03<00:00, 250.37it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 1\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:05<00:00, 370.92it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2667.27it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2889.48it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2791.71it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.494418660028031, Dev loss: 0.9453121938859838\n","Saving probe parameters\n","[epoch 1] Train loss: 0.9614783934224433, Dev loss: 0.9198630250999669\n","Saving probe parameters\n","[epoch 2] Train loss: 1.0813182271569366, Dev loss: 0.9519187207536709\n","[epoch 3] Train loss: 0.7244338515558968, Dev loss: 0.7280542933629132\n","Saving probe parameters\n","[epoch 4] Train loss: 0.7020056798469596, Dev loss: 0.7263980853008304\n","Saving probe parameters\n","[epoch 5] Train loss: 0.6964789051812583, Dev loss: 0.7181110156428621\n","Saving probe parameters\n","[epoch 6] Train loss: 0.6935513982651024, Dev loss: 0.7184968101577474\n","[epoch 7] Train loss: 0.6713042676208011, Dev loss: 0.7070206690250268\n","Saving probe parameters\n","[epoch 8] Train loss: 0.6667399619279094, Dev loss: 0.7061936377291365\n","Saving probe parameters\n","[epoch 9] Train loss: 0.6651534173007927, Dev loss: 0.7065357096020044\n","[epoch 10] Train loss: 0.6616527762015919, Dev loss: 0.7054463228579625\n","Saving probe parameters\n","[epoch 11] Train loss: 0.6612080321323758, Dev loss: 0.7053476122218378\n","[epoch 12] Train loss: 0.6610211187090725, Dev loss: 0.7052877085888817\n","Saving probe parameters\n","[epoch 13] Train loss: 0.6605638965360348, Dev loss: 0.7052617797519023\n","[epoch 14] Train loss: 0.6605328588834971, Dev loss: 0.7052639884639944\n","[epoch 15] Train loss: 0.6604790087708218, Dev loss: 0.705262782119428\n","[epoch 16] Train loss: 0.6604769797426431, Dev loss: 0.7052627723214041\n","[epoch 17] Train loss: 0.6604750021859066, Dev loss: 0.7052630077708851\n","Early stopping\n","[training]:  57% 17/30 [01:18<01:00,  4.62s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 617.12it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-distance-2\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 2\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:49<00:00, 308.06it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 2\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:03<00:00, 206.99it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 2\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 289.17it/s]\n","[computing labels]: 100% 15346/15346 [03:40<00:00, 69.44it/s]\n","[computing labels]: 100% 803/803 [00:10<00:00, 78.97it/s]\n","[computing labels]: 100% 1905/1905 [00:24<00:00, 76.65it/s]\n","Constructing TwoWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.8251527927385756, Dev loss: 1.0391867674451094\n","Saving probe parameters\n","[epoch 1] Train loss: 1.1526302025120214, Dev loss: 1.1080878122360591\n","[epoch 2] Train loss: 0.9115774647036448, Dev loss: 0.8900101578250472\n","Saving probe parameters\n","[epoch 3] Train loss: 0.8855117951411398, Dev loss: 0.8872803489713562\n","Saving probe parameters\n","[epoch 4] Train loss: 0.8804130610751, Dev loss: 0.8852863184096359\n","Saving probe parameters\n","[epoch 5] Train loss: 0.8781885948203525, Dev loss: 0.8877196062546442\n","[epoch 6] Train loss: 0.8560186834265725, Dev loss: 0.8721436207202422\n","Saving probe parameters\n","[epoch 7] Train loss: 0.8513238413244093, Dev loss: 0.8710186499290419\n","Saving probe parameters\n","[epoch 8] Train loss: 0.8499865200378803, Dev loss: 0.8705890246969676\n","Saving probe parameters\n","[epoch 9] Train loss: 0.8491996147479411, Dev loss: 0.870756570013196\n","[epoch 10] Train loss: 0.8458156855712576, Dev loss: 0.8695322733887403\n","Saving probe parameters\n","[epoch 11] Train loss: 0.8455305213523039, Dev loss: 0.869513683568496\n","[epoch 12] Train loss: 0.8450604338044995, Dev loss: 0.8694789994549781\n","[epoch 13] Train loss: 0.8450066666551508, Dev loss: 0.8694767393774885\n","[epoch 14] Train loss: 0.8450047529832831, Dev loss: 0.8694761601064451\n","[epoch 15] Train loss: 0.8450029581478362, Dev loss: 0.8694756007283592\n","Early stopping\n","[training]:  50% 15/30 [01:42<01:42,  6.84s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 464.89it/s]\n","Reporting spearmanr on split dev\n","Reporting uuas on split dev\n","[uuas,tikz]: 81it [00:22,  3.66it/s]\n","Constructing new results directory at results/parse-depth-2\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 2\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:42<00:00, 357.41it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 2\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 381.06it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 2\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:07<00:00, 268.84it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2670.97it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2888.26it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2790.65it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.4350369418442646, Dev loss: 0.9779047761135647\n","Saving probe parameters\n","[epoch 1] Train loss: 0.9295203450853101, Dev loss: 0.8570393432270397\n","Saving probe parameters\n","[epoch 2] Train loss: 0.9820305541396591, Dev loss: 0.8570399800985866\n","[epoch 3] Train loss: 0.6662931664428452, Dev loss: 0.6639353216510929\n","Saving probe parameters\n","[epoch 4] Train loss: 0.6451666927020708, Dev loss: 0.6566918172396877\n","Saving probe parameters\n","[epoch 5] Train loss: 0.6388783252458288, Dev loss: 0.6549071330359092\n","Saving probe parameters\n","[epoch 6] Train loss: 0.634919460214724, Dev loss: 0.6581310917104909\n","[epoch 7] Train loss: 0.610719168635184, Dev loss: 0.6431365835562738\n","Saving probe parameters\n","[epoch 8] Train loss: 0.6061771528888336, Dev loss: 0.6425670354185188\n","Saving probe parameters\n","[epoch 9] Train loss: 0.6046709705328174, Dev loss: 0.6418026455609618\n","Saving probe parameters\n","[epoch 10] Train loss: 0.6034957957084434, Dev loss: 0.6415416891518447\n","Saving probe parameters\n","[epoch 11] Train loss: 0.6028452890568383, Dev loss: 0.6415784825126677\n","[epoch 12] Train loss: 0.599504706462794, Dev loss: 0.6408939124044416\n","Saving probe parameters\n","[epoch 13] Train loss: 0.5991199333664958, Dev loss: 0.6407950874580393\n","[epoch 14] Train loss: 0.5989718958123728, Dev loss: 0.6409010896053291\n","[epoch 15] Train loss: 0.5985257967065587, Dev loss: 0.6408310946016799\n","[epoch 16] Train loss: 0.5984620941550639, Dev loss: 0.6408273838228484\n","[epoch 17] Train loss: 0.5984597514820087, Dev loss: 0.6408274247964025\n","Early stopping\n","[training]:  57% 17/30 [01:17<00:59,  4.59s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 614.72it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-distance-3\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 3\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:50<00:00, 301.38it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 3\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 318.42it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 3\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:08<00:00, 218.48it/s]\n","[computing labels]: 100% 15346/15346 [03:37<00:00, 70.42it/s]\n","[computing labels]: 100% 803/803 [00:10<00:00, 80.07it/s]\n","[computing labels]: 100% 1905/1905 [00:24<00:00, 78.00it/s] \n","Constructing TwoWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.5731938082904933, Dev loss: 0.9959848238848809\n","Saving probe parameters\n","[epoch 1] Train loss: 1.1021043328655973, Dev loss: 1.0365956631276854\n","[epoch 2] Train loss: 0.8510474212536613, Dev loss: 0.8321195972960438\n","Saving probe parameters\n","[epoch 3] Train loss: 0.8244896400833975, Dev loss: 0.823914724447362\n","Saving probe parameters\n","[epoch 4] Train loss: 0.8194841165267922, Dev loss: 0.8223544711045281\n","Saving probe parameters\n","[epoch 5] Train loss: 0.8163129749376398, Dev loss: 0.8189187406157498\n","Saving probe parameters\n","[epoch 6] Train loss: 0.8146312726487024, Dev loss: 0.8190854361760957\n","[epoch 7] Train loss: 0.794126103105499, Dev loss: 0.807101166263167\n","Saving probe parameters\n","[epoch 8] Train loss: 0.7898061669946385, Dev loss: 0.8057381602034326\n","Saving probe parameters\n","[epoch 9] Train loss: 0.7884761662584512, Dev loss: 0.805034408236797\n","Saving probe parameters\n","[epoch 10] Train loss: 0.787762856166521, Dev loss: 0.8064352251672804\n","[epoch 11] Train loss: 0.7846760158508989, Dev loss: 0.8048973035990524\n","Saving probe parameters\n","[epoch 12] Train loss: 0.7843611475605085, Dev loss: 0.8048153371917801\n","[epoch 13] Train loss: 0.7842450007207854, Dev loss: 0.8047380070312234\n","Saving probe parameters\n","[epoch 14] Train loss: 0.7838351097471102, Dev loss: 0.8046728258263575\n","[epoch 15] Train loss: 0.7838184117929078, Dev loss: 0.8046654401947819\n","[epoch 16] Train loss: 0.7837725071277516, Dev loss: 0.8046578721121269\n","[epoch 17] Train loss: 0.7837708447384396, Dev loss: 0.8046566804645962\n","[epoch 18] Train loss: 0.7837695229648534, Dev loss: 0.8046553351662376\n","Early stopping\n","[training]:  60% 18/30 [02:01<01:21,  6.75s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 479.76it/s]\n","Reporting spearmanr on split dev\n","Reporting uuas on split dev\n","[uuas,tikz]: 81it [00:22,  3.65it/s]\n","Constructing new results directory at results/parse-depth-3\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 3\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:54<00:00, 282.75it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 3\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 375.00it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 3\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:05<00:00, 354.06it/s]\n","[computing labels]: 100% 15346/15346 [00:06<00:00, 2553.64it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2814.09it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2706.42it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.4083557811567031, Dev loss: 0.8101287609613402\n","Saving probe parameters\n","[epoch 1] Train loss: 0.9262628741732294, Dev loss: 0.7927336312765499\n","Saving probe parameters\n","[epoch 2] Train loss: 0.982089668555069, Dev loss: 0.8644130179475283\n","[epoch 3] Train loss: 0.637191815325323, Dev loss: 0.6428059124263702\n","Saving probe parameters\n","[epoch 4] Train loss: 0.6128507968609761, Dev loss: 0.6346959830221174\n","Saving probe parameters\n","[epoch 5] Train loss: 0.60727604131849, Dev loss: 0.6354962850121751\n","[epoch 6] Train loss: 0.5820698737942782, Dev loss: 0.6202801601082124\n","Saving probe parameters\n","[epoch 7] Train loss: 0.5776617118871991, Dev loss: 0.6204171029301093\n","[epoch 8] Train loss: 0.5736002650329906, Dev loss: 0.618655843425955\n","Saving probe parameters\n","[epoch 9] Train loss: 0.573139802303088, Dev loss: 0.6185471937338709\n","Saving probe parameters\n","[epoch 10] Train loss: 0.572934473709008, Dev loss: 0.618521889892046\n","[epoch 11] Train loss: 0.5724438738670682, Dev loss: 0.6184268318404297\n","Saving probe parameters\n","[epoch 12] Train loss: 0.5724003071208891, Dev loss: 0.618398219235659\n","[epoch 13] Train loss: 0.5723399810369674, Dev loss: 0.6183986966666367\n","[epoch 14] Train loss: 0.5723368958576739, Dev loss: 0.6183993664951728\n","[epoch 15] Train loss: 0.5723342322532627, Dev loss: 0.6183987890055883\n","[epoch 16] Train loss: 0.5723317447051097, Dev loss: 0.6183975963188731\n","Early stopping\n","[training]:  53% 16/30 [01:14<01:05,  4.68s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 617.39it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-distance-4\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 4\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:52<00:00, 292.02it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 4\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 320.96it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 4\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 299.40it/s]\n","[computing labels]: 100% 15346/15346 [03:46<00:00, 67.66it/s]\n","[computing labels]: 100% 803/803 [00:10<00:00, 77.13it/s]\n","[computing labels]: 100% 1905/1905 [00:25<00:00, 74.78it/s]\n","Constructing TwoWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.6002085738366638, Dev loss: 0.9686100194938156\n","Saving probe parameters\n","[epoch 1] Train loss: 1.0390998756933691, Dev loss: 0.9476223366049723\n","Saving probe parameters\n","[epoch 2] Train loss: 1.0705461279596762, Dev loss: 0.9921843010936846\n","[epoch 3] Train loss: 0.8147946091685102, Dev loss: 0.7902326913432196\n","Saving probe parameters\n","[epoch 4] Train loss: 0.7849433322035473, Dev loss: 0.7825204174070252\n","Saving probe parameters\n","[epoch 5] Train loss: 0.7788092195793499, Dev loss: 0.7856437251398602\n","[epoch 6] Train loss: 0.7550382475086721, Dev loss: 0.7674608969896253\n","Saving probe parameters\n","[epoch 7] Train loss: 0.750117275529372, Dev loss: 0.7670926738943288\n","Saving probe parameters\n","[epoch 8] Train loss: 0.7484929373626927, Dev loss: 0.7656544216840087\n","Saving probe parameters\n","[epoch 9] Train loss: 0.7476095485668612, Dev loss: 0.7654851596352469\n","Saving probe parameters\n","[epoch 10] Train loss: 0.7468711901220647, Dev loss: 0.7655064749391112\n","[epoch 11] Train loss: 0.7435182770958131, Dev loss: 0.7648284289786409\n","Saving probe parameters\n","[epoch 12] Train loss: 0.7431844974549143, Dev loss: 0.7647784839976918\n","[epoch 13] Train loss: 0.7427074699471458, Dev loss: 0.7647500789328797\n","[epoch 14] Train loss: 0.7426832528743846, Dev loss: 0.7647404053142923\n","[epoch 15] Train loss: 0.7426305363297261, Dev loss: 0.7647366425762437\n","[epoch 16] Train loss: 0.7426286830936901, Dev loss: 0.7647357298754814\n","Early stopping\n","[training]:  53% 16/30 [01:49<01:35,  6.84s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 475.01it/s]\n","Reporting spearmanr on split dev\n","Reporting uuas on split dev\n","[uuas,tikz]: 81it [00:21,  3.71it/s]\n","Constructing new results directory at results/parse-depth-4\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 4\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:55<00:00, 275.07it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 4\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 373.85it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 4\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:05<00:00, 362.72it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2589.54it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2851.48it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2707.30it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.4711931924162454, Dev loss: 0.9976687309602427\n","Saving probe parameters\n","[epoch 1] Train loss: 0.9288190620501412, Dev loss: 0.760869215909452\n","Saving probe parameters\n","[epoch 2] Train loss: 0.8986515256520529, Dev loss: 2.13741137170851\n","[epoch 3] Train loss: 0.6437668445196392, Dev loss: 0.6181859302045696\n","Saving probe parameters\n","[epoch 4] Train loss: 0.5866686308475605, Dev loss: 0.6133575581969835\n","Saving probe parameters\n","[epoch 5] Train loss: 0.5794446810615835, Dev loss: 0.6076256249048938\n","Saving probe parameters\n","[epoch 6] Train loss: 0.5749603308398394, Dev loss: 0.6083034602078524\n","[epoch 7] Train loss: 0.5500137808579876, Dev loss: 0.5902318063738338\n","Saving probe parameters\n","[epoch 8] Train loss: 0.5450314698032244, Dev loss: 0.588898962788089\n","Saving probe parameters\n","[epoch 9] Train loss: 0.5432005108653466, Dev loss: 0.588537321292597\n","Saving probe parameters\n","[epoch 10] Train loss: 0.5420154026740691, Dev loss: 0.588535023804471\n","[epoch 11] Train loss: 0.5383329313332389, Dev loss: 0.5878224975590688\n","Saving probe parameters\n","[epoch 12] Train loss: 0.5379357907974966, Dev loss: 0.5877186661194151\n","Saving probe parameters\n","[epoch 13] Train loss: 0.5377445339799223, Dev loss: 0.5878259440881675\n","[epoch 14] Train loss: 0.5372806259259926, Dev loss: 0.5877965657529914\n","[epoch 15] Train loss: 0.5372086636761899, Dev loss: 0.5877953139812236\n","[epoch 16] Train loss: 0.5372052868512841, Dev loss: 0.5877968326749125\n","[epoch 17] Train loss: 0.5372021745768517, Dev loss: 0.5877977281549057\n","Early stopping\n","[training]:  57% 17/30 [01:19<01:00,  4.68s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 612.24it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-distance-5\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 5\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:53<00:00, 285.43it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 5\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 315.38it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 5\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 297.19it/s]\n","[computing labels]: 100% 15346/15346 [03:32<00:00, 72.28it/s]\n","[computing labels]: 100% 803/803 [00:09<00:00, 82.77it/s]\n","[computing labels]: 100% 1905/1905 [00:23<00:00, 80.38it/s]\n","Constructing TwoWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.5296779955659248, Dev loss: 0.9473092505525088\n","Saving probe parameters\n","[epoch 1] Train loss: 0.9782064484909835, Dev loss: 1.0085561486288144\n","[epoch 2] Train loss: 0.8046142075559889, Dev loss: 0.7828481693196564\n","Saving probe parameters\n","[epoch 3] Train loss: 0.7738959012155223, Dev loss: 0.7767865176812501\n","Saving probe parameters\n","[epoch 4] Train loss: 0.7674804640363159, Dev loss: 0.7741724070101271\n","Saving probe parameters\n","[epoch 5] Train loss: 0.7647587319916858, Dev loss: 0.7779392673544687\n","[epoch 6] Train loss: 0.742469766965578, Dev loss: 0.7604103959809204\n","Saving probe parameters\n","[epoch 7] Train loss: 0.737787563238712, Dev loss: 0.760127603191219\n","Saving probe parameters\n","[epoch 8] Train loss: 0.7363623013074435, Dev loss: 0.7595842344823246\n","Saving probe parameters\n","[epoch 9] Train loss: 0.7355614045787072, Dev loss: 0.7596422367048442\n","[epoch 10] Train loss: 0.7322374682033076, Dev loss: 0.7587992159248438\n","Saving probe parameters\n","[epoch 11] Train loss: 0.7319629900492451, Dev loss: 0.7586726925589822\n","Saving probe parameters\n","[epoch 12] Train loss: 0.7318119498130692, Dev loss: 0.7587346947504902\n","[epoch 13] Train loss: 0.7313994582032157, Dev loss: 0.7586482972611823\n","[epoch 14] Train loss: 0.7313458224746126, Dev loss: 0.7586382329092821\n","[epoch 15] Train loss: 0.7313436030036512, Dev loss: 0.7586370298307236\n","[epoch 16] Train loss: 0.7313416887880164, Dev loss: 0.7586366542398113\n","Early stopping\n","[training]:  53% 16/30 [01:49<01:35,  6.85s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 467.05it/s]\n","Reporting spearmanr on split dev\n","Reporting uuas on split dev\n","[uuas,tikz]: 81it [00:21,  3.73it/s]\n","Constructing new results directory at results/parse-depth-5\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 5\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:44<00:00, 341.45it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 5\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 293.19it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 5\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:05<00:00, 319.19it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2665.16it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2875.11it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2804.67it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.388184518014283, Dev loss: 0.737559733325488\n","Saving probe parameters\n","[epoch 1] Train loss: 0.9237404112925853, Dev loss: 1.1463479924469184\n","[epoch 2] Train loss: 0.5983871975358953, Dev loss: 0.596651081724155\n","Saving probe parameters\n","[epoch 3] Train loss: 0.5645075072121095, Dev loss: 0.5820481498095939\n","Saving probe parameters\n","[epoch 4] Train loss: 0.5563556011972536, Dev loss: 0.585620417244556\n","[epoch 5] Train loss: 0.5322631569398393, Dev loss: 0.5696300952550335\n","Saving probe parameters\n","[epoch 6] Train loss: 0.5269869389317111, Dev loss: 0.5698201062521928\n","[epoch 7] Train loss: 0.5227614782258303, Dev loss: 0.5680709962975489\n","Saving probe parameters\n","[epoch 8] Train loss: 0.522328331994681, Dev loss: 0.5681339460767221\n","[epoch 9] Train loss: 0.5218132985519117, Dev loss: 0.5680084869840819\n","[epoch 10] Train loss: 0.5217701650793761, Dev loss: 0.5679524975131784\n","Saving probe parameters\n","[epoch 11] Train loss: 0.5217092048386994, Dev loss: 0.5679490925514534\n","[epoch 12] Train loss: 0.5217059602967984, Dev loss: 0.5679472413187752\n","[epoch 13] Train loss: 0.5217029302943317, Dev loss: 0.5679455608092387\n","[epoch 14] Train loss: 0.5216998888339148, Dev loss: 0.5679427392752946\n","[epoch 15] Train loss: 0.5216969576028619, Dev loss: 0.5679412965905176\n","Early stopping\n","[training]:  50% 15/30 [01:09<01:09,  4.63s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 618.60it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-distance-6\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 6\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [01:01<00:00, 248.53it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 6\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:03<00:00, 240.98it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 6\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:07<00:00, 251.88it/s]\n","[computing labels]: 100% 15346/15346 [03:36<00:00, 70.85it/s]\n","[computing labels]: 100% 803/803 [00:09<00:00, 80.71it/s]\n","[computing labels]: 100% 1905/1905 [00:24<00:00, 78.52it/s]\n","Constructing TwoWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.4386634081543836, Dev loss: 0.8931847896849084\n","Saving probe parameters\n","[epoch 1] Train loss: 0.9747633996476535, Dev loss: 0.9150795105236998\n","[epoch 2] Train loss: 0.7888525482512322, Dev loss: 0.7605173961905436\n","Saving probe parameters\n","[epoch 3] Train loss: 0.7568009523622654, Dev loss: 0.758063679465915\n","Saving probe parameters\n","[epoch 4] Train loss: 0.7503759831007559, Dev loss: 0.7592056343890958\n","[epoch 5] Train loss: 0.7270667015084632, Dev loss: 0.7442476109579521\n","Saving probe parameters\n","[epoch 6] Train loss: 0.7223939085727594, Dev loss: 0.7417940668863793\n","Saving probe parameters\n","[epoch 7] Train loss: 0.720937382067165, Dev loss: 0.7411843518985164\n","Saving probe parameters\n","[epoch 8] Train loss: 0.7199193807370998, Dev loss: 0.7409107287229963\n","Saving probe parameters\n","[epoch 9] Train loss: 0.7193732865549946, Dev loss: 0.7404409013085467\n","Saving probe parameters\n","[epoch 10] Train loss: 0.7187433897804192, Dev loss: 0.74051709905508\n","[epoch 11] Train loss: 0.7156146436475269, Dev loss: 0.7398499988232871\n","Saving probe parameters\n","[epoch 12] Train loss: 0.7153353868835243, Dev loss: 0.7397443891907688\n","Saving probe parameters\n","[epoch 13] Train loss: 0.7152099035156918, Dev loss: 0.7397033019202436\n","[epoch 14] Train loss: 0.7147918404057519, Dev loss: 0.7396286377128896\n","Saving probe parameters\n","[epoch 15] Train loss: 0.714775902311727, Dev loss: 0.739617911994383\n","[epoch 16] Train loss: 0.7147306692455764, Dev loss: 0.7396125965664723\n","[epoch 17] Train loss: 0.7147294050646965, Dev loss: 0.7396118729972602\n","[epoch 18] Train loss: 0.7147283068570789, Dev loss: 0.7396111917376964\n","[epoch 19] Train loss: 0.7147271706012988, Dev loss: 0.7396104169515417\n","Early stopping\n","[training]:  63% 19/30 [02:08<01:14,  6.77s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 477.59it/s]\n","Reporting spearmanr on split dev\n","Reporting uuas on split dev\n","[uuas,tikz]: 81it [00:21,  3.81it/s]\n","Constructing new results directory at results/parse-depth-6\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 6\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:50<00:00, 306.27it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 6\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 350.19it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 6\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 309.69it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2620.63it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2847.61it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2752.84it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.397233799323255, Dev loss: 1.007440403716205\n","Saving probe parameters\n","[epoch 1] Train loss: 0.8712137279276834, Dev loss: 0.6996454877841517\n","Saving probe parameters\n","[epoch 2] Train loss: 0.9438697924191989, Dev loss: 0.7151703460427328\n","[epoch 3] Train loss: 0.5701557816232368, Dev loss: 0.5755440304021016\n","Saving probe parameters\n","[epoch 4] Train loss: 0.5444307098111506, Dev loss: 0.574603647550343\n","Saving probe parameters\n","[epoch 5] Train loss: 0.5370534997121243, Dev loss: 0.5633431428099331\n","Saving probe parameters\n","[epoch 6] Train loss: 0.5329088800254552, Dev loss: 0.5649280720303395\n","[epoch 7] Train loss: 0.50851789251636, Dev loss: 0.5527062252776264\n","Saving probe parameters\n","[epoch 8] Train loss: 0.5039594539153627, Dev loss: 0.55210493718405\n","Saving probe parameters\n","[epoch 9] Train loss: 0.5021706433459644, Dev loss: 0.5517700410275204\n","Saving probe parameters\n","[epoch 10] Train loss: 0.5009938325748968, Dev loss: 0.5518249319321191\n","[epoch 11] Train loss: 0.4975552758849865, Dev loss: 0.5511695715142959\n","Saving probe parameters\n","[epoch 12] Train loss: 0.49715025704919663, Dev loss: 0.5510258837921979\n","Saving probe parameters\n","[epoch 13] Train loss: 0.49698611559868483, Dev loss: 0.5511281053868504\n","[epoch 14] Train loss: 0.4965266922563334, Dev loss: 0.5510328893792139\n","[epoch 15] Train loss: 0.49646411660782414, Dev loss: 0.5510276976142399\n","[epoch 16] Train loss: 0.4964610852148672, Dev loss: 0.5510241925939082\n","[epoch 17] Train loss: 0.49645855458482185, Dev loss: 0.5510209307427127\n","Early stopping\n","[training]:  57% 17/30 [01:18<01:00,  4.63s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 619.44it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-distance-7\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 7\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [01:00<00:00, 253.04it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 7\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:03<00:00, 237.02it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 7\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:07<00:00, 238.51it/s]\n","[computing labels]: 100% 15346/15346 [03:37<00:00, 70.57it/s]\n","[computing labels]: 100% 803/803 [00:10<00:00, 80.22it/s]\n","[computing labels]: 100% 1905/1905 [00:24<00:00, 78.33it/s]\n","Constructing TwoWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.508136096560596, Dev loss: 0.940404507172657\n","Saving probe parameters\n","[epoch 1] Train loss: 0.9409273054179352, Dev loss: 0.9098213416701681\n","Saving probe parameters\n","[epoch 2] Train loss: 0.98096109347006, Dev loss: 0.91729079058874\n","[epoch 3] Train loss: 0.763837630755274, Dev loss: 0.7443677535834972\n","Saving probe parameters\n","[epoch 4] Train loss: 0.7316176498260956, Dev loss: 0.7385630272096892\n","Saving probe parameters\n","[epoch 5] Train loss: 0.7253359631082621, Dev loss: 0.7322779789956688\n","Saving probe parameters\n","[epoch 6] Train loss: 0.7210277405801846, Dev loss: 0.7305567760396271\n","Saving probe parameters\n","[epoch 7] Train loss: 0.7191450144839725, Dev loss: 0.7316933144371062\n","[epoch 8] Train loss: 0.6967688304697786, Dev loss: 0.7162620469018501\n","Saving probe parameters\n","[epoch 9] Train loss: 0.6919415799390379, Dev loss: 0.7157935092636242\n","Saving probe parameters\n","[epoch 10] Train loss: 0.6904445288778828, Dev loss: 0.714677496686819\n","Saving probe parameters\n","[epoch 11] Train loss: 0.6896291317598583, Dev loss: 0.7148642382615827\n","[epoch 12] Train loss: 0.6862679837067901, Dev loss: 0.714091053638482\n","Saving probe parameters\n","[epoch 13] Train loss: 0.6859506461854306, Dev loss: 0.7139419664629963\n","Saving probe parameters\n","[epoch 14] Train loss: 0.6858123084890723, Dev loss: 0.71390643452351\n","[epoch 15] Train loss: 0.6853766468688933, Dev loss: 0.7138852869736896\n","[epoch 16] Train loss: 0.6853254867411026, Dev loss: 0.7138804152774929\n","[epoch 17] Train loss: 0.6853236131837125, Dev loss: 0.713878822653261\n","[epoch 18] Train loss: 0.6853217571045512, Dev loss: 0.7138770817225778\n","Early stopping\n","[training]:  60% 18/30 [02:01<01:21,  6.76s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 470.81it/s]\n","Reporting spearmanr on split dev\n","Reporting uuas on split dev\n","[uuas,tikz]: 81it [00:21,  3.75it/s]\n","Constructing new results directory at results/parse-depth-7\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 7\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:46<00:00, 333.05it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 7\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 367.21it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 7\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:05<00:00, 358.75it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2576.13it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2856.93it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2703.99it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.4943997888852172, Dev loss: 0.7971846323975293\n","Saving probe parameters\n","[epoch 1] Train loss: 0.8825284756101531, Dev loss: 0.7084297658794398\n","Saving probe parameters\n","[epoch 2] Train loss: 0.8679132921730199, Dev loss: 0.741812447385206\n","[epoch 3] Train loss: 0.5581957337816831, Dev loss: 0.5559690500404292\n","Saving probe parameters\n","[epoch 4] Train loss: 0.5307569381514258, Dev loss: 0.5545743052125126\n","Saving probe parameters\n","[epoch 5] Train loss: 0.5233259529951233, Dev loss: 0.5494347660805784\n","Saving probe parameters\n","[epoch 6] Train loss: 0.519534894560301, Dev loss: 0.5484974345709586\n","Saving probe parameters\n","[epoch 7] Train loss: 0.5160665365267838, Dev loss: 0.5538653852336879\n","[epoch 8] Train loss: 0.4910749414823799, Dev loss: 0.5363828058112158\n","Saving probe parameters\n","[epoch 9] Train loss: 0.4860758368636178, Dev loss: 0.5354312885445943\n","Saving probe parameters\n","[epoch 10] Train loss: 0.4842293308468852, Dev loss: 0.5349220472433202\n","Saving probe parameters\n","[epoch 11] Train loss: 0.4831081898507931, Dev loss: 0.5349717244116188\n","[epoch 12] Train loss: 0.4793269464436122, Dev loss: 0.5342790825132415\n","Saving probe parameters\n","[epoch 13] Train loss: 0.47892283827792737, Dev loss: 0.5341380494617733\n","Saving probe parameters\n","[epoch 14] Train loss: 0.4787520263895099, Dev loss: 0.5343645414706334\n","[epoch 15] Train loss: 0.4782687335658785, Dev loss: 0.534310427282103\n","[epoch 16] Train loss: 0.47820112783843904, Dev loss: 0.5343077699392849\n","[epoch 17] Train loss: 0.4781982284566033, Dev loss: 0.5343058551679067\n","[epoch 18] Train loss: 0.4781955621799652, Dev loss: 0.5343049700797569\n","Early stopping\n","[training]:  60% 18/30 [01:23<00:55,  4.62s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 620.87it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-distance-8\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 8\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [01:02<00:00, 244.93it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 8\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:03<00:00, 240.64it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 8\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:07<00:00, 239.21it/s]\n","[computing labels]: 100% 15346/15346 [03:32<00:00, 72.30it/s]\n","[computing labels]: 100% 803/803 [00:09<00:00, 82.43it/s]\n","[computing labels]: 100% 1905/1905 [00:23<00:00, 80.19it/s] \n","Constructing TwoWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.555239545433614, Dev loss: 0.8925654995040608\n","Saving probe parameters\n","[epoch 1] Train loss: 0.9807739059259819, Dev loss: 0.9352539182451564\n","[epoch 2] Train loss: 0.7494891657444608, Dev loss: 0.7264338682775628\n","Saving probe parameters\n","[epoch 3] Train loss: 0.7148993213841988, Dev loss: 0.715492117746384\n","Saving probe parameters\n","[epoch 4] Train loss: 0.7072388316077047, Dev loss: 0.7160905452623759\n","[epoch 5] Train loss: 0.6820152221626492, Dev loss: 0.7008007389225371\n","Saving probe parameters\n","[epoch 6] Train loss: 0.6769504145197556, Dev loss: 0.6999479890018144\n","Saving probe parameters\n","[epoch 7] Train loss: 0.6751092657277905, Dev loss: 0.6997068547371167\n","Saving probe parameters\n","[epoch 8] Train loss: 0.6741531009734975, Dev loss: 0.7002005281662139\n","[epoch 9] Train loss: 0.6704005912309455, Dev loss: 0.6981943268259316\n","Saving probe parameters\n","[epoch 10] Train loss: 0.6700486213990332, Dev loss: 0.6980440809599043\n","Saving probe parameters\n","[epoch 11] Train loss: 0.6698949249070704, Dev loss: 0.6980410628716646\n","[epoch 12] Train loss: 0.6694186771924284, Dev loss: 0.6979474944165753\n","[epoch 13] Train loss: 0.6693970718797674, Dev loss: 0.697942555915671\n","Saving probe parameters\n","[epoch 14] Train loss: 0.6693473501403064, Dev loss: 0.6979390131877933\n","[epoch 15] Train loss: 0.6693450610360809, Dev loss: 0.6979389652368586\n","[epoch 16] Train loss: 0.6693433548502112, Dev loss: 0.6979382577007764\n","[epoch 17] Train loss: 0.6693419008169245, Dev loss: 0.6979374291739457\n","[epoch 18] Train loss: 0.6693404941535223, Dev loss: 0.6979370167662168\n","Early stopping\n","[training]:  60% 18/30 [02:01<01:20,  6.75s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 477.19it/s]\n","Reporting spearmanr on split dev\n","Reporting uuas on split dev\n","[uuas,tikz]: 81it [00:21,  3.81it/s]\n","Constructing new results directory at results/parse-depth-8\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 8\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:47<00:00, 322.38it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 8\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 339.09it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 8\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:05<00:00, 359.54it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2655.06it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2923.63it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2749.52it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.4601416349504228, Dev loss: 0.8191945285607097\n","Saving probe parameters\n","[epoch 1] Train loss: 0.8862110029745331, Dev loss: 0.7352915317896442\n","Saving probe parameters\n","[epoch 2] Train loss: 0.8570069350398349, Dev loss: 0.6758097943155139\n","Saving probe parameters\n","[epoch 3] Train loss: 0.9492873316185269, Dev loss: 1.128492823870363\n","[epoch 4] Train loss: 0.5693329722601976, Dev loss: 0.5463540649057771\n","Saving probe parameters\n","[epoch 5] Train loss: 0.5229798450504772, Dev loss: 0.5407701577819596\n","Saving probe parameters\n","[epoch 6] Train loss: 0.5156830150270406, Dev loss: 0.5420939129583565\n","[epoch 7] Train loss: 0.4893141436977677, Dev loss: 0.5287317125170792\n","Saving probe parameters\n","[epoch 8] Train loss: 0.48359148211512126, Dev loss: 0.5270339047181354\n","Saving probe parameters\n","[epoch 9] Train loss: 0.48146022818754414, Dev loss: 0.5260774507320685\n","Saving probe parameters\n","[epoch 10] Train loss: 0.48002309294578444, Dev loss: 0.5265352589404152\n","[epoch 11] Train loss: 0.47603855009699186, Dev loss: 0.5255331470541758\n","Saving probe parameters\n","[epoch 12] Train loss: 0.47560180599183316, Dev loss: 0.5254349764969993\n","[epoch 13] Train loss: 0.4754053678503873, Dev loss: 0.5253305705368593\n","Saving probe parameters\n","[epoch 14] Train loss: 0.47525513994014823, Dev loss: 0.5252193570285478\n","Saving probe parameters\n","[epoch 15] Train loss: 0.47512602478277416, Dev loss: 0.5251561927320354\n","[epoch 16] Train loss: 0.47498414405520484, Dev loss: 0.5251573168325839\n","[epoch 17] Train loss: 0.4745101358998355, Dev loss: 0.5251667404531096\n","[epoch 18] Train loss: 0.4744419772855216, Dev loss: 0.5251628043197308\n","[epoch 19] Train loss: 0.4744390309532789, Dev loss: 0.5251630905407897\n","Early stopping\n","[training]:  63% 19/30 [01:26<00:50,  4.56s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 627.82it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-distance-9\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 9\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [01:01<00:00, 248.49it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 9\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 271.29it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 9\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:07<00:00, 254.51it/s]\n","[computing labels]: 100% 15346/15346 [03:32<00:00, 72.34it/s]\n","[computing labels]: 100% 803/803 [00:09<00:00, 82.71it/s]\n","[computing labels]: 100% 1905/1905 [00:23<00:00, 80.30it/s] \n","Constructing TwoWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.5810553502744418, Dev loss: 0.947017419085853\n","Saving probe parameters\n","[epoch 1] Train loss: 0.992776518180009, Dev loss: 0.9101110261819728\n","Saving probe parameters\n","[epoch 2] Train loss: 0.9965165118482578, Dev loss: 0.9485528958986883\n","[epoch 3] Train loss: 0.7762615179341292, Dev loss: 0.7500604677615991\n","Saving probe parameters\n","[epoch 4] Train loss: 0.7401780983964514, Dev loss: 0.7430320703523097\n","Saving probe parameters\n","[epoch 5] Train loss: 0.7318618530619957, Dev loss: 0.7463470443545065\n","[epoch 6] Train loss: 0.7069581668752588, Dev loss: 0.725997608001918\n","Saving probe parameters\n","[epoch 7] Train loss: 0.7011635746434477, Dev loss: 0.7252640397581336\n","Saving probe parameters\n","[epoch 8] Train loss: 0.6993844311970333, Dev loss: 0.7248876136385489\n","Saving probe parameters\n","[epoch 9] Train loss: 0.6982455257951211, Dev loss: 0.7247640682781025\n","Saving probe parameters\n","[epoch 10] Train loss: 0.6975202234164531, Dev loss: 0.724583943486956\n","Saving probe parameters\n","[epoch 11] Train loss: 0.6969552960309432, Dev loss: 0.7246723022140275\n","[epoch 12] Train loss: 0.6932789043172715, Dev loss: 0.7240277096759041\n","Saving probe parameters\n","[epoch 13] Train loss: 0.6930049197950031, Dev loss: 0.7239068583266376\n","Saving probe parameters\n","[epoch 14] Train loss: 0.6928828927508299, Dev loss: 0.7238756541445721\n","[epoch 15] Train loss: 0.6924215887976519, Dev loss: 0.7238504334374947\n","[epoch 16] Train loss: 0.6923648253827025, Dev loss: 0.7238434242875609\n","[epoch 17] Train loss: 0.6923629169620716, Dev loss: 0.7238411149230425\n","[epoch 18] Train loss: 0.6923612363954015, Dev loss: 0.7238395754456669\n","Early stopping\n","[training]:  60% 18/30 [02:01<01:21,  6.75s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 485.31it/s]\n","Reporting spearmanr on split dev\n","Reporting uuas on split dev\n","[uuas,tikz]: 81it [00:20,  3.89it/s]\n","Constructing new results directory at results/parse-depth-9\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 9\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:45<00:00, 339.80it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 9\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 363.33it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 9\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:05<00:00, 338.49it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2667.91it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2993.27it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2820.76it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.4603059465223631, Dev loss: 0.7112374100857327\n","Saving probe parameters\n","[epoch 1] Train loss: 0.8975805415178735, Dev loss: 0.7293270058827858\n","[epoch 2] Train loss: 0.5646166739618547, Dev loss: 0.5636379377334234\n","Saving probe parameters\n","[epoch 3] Train loss: 0.5346441919421739, Dev loss: 0.5546662305687017\n","Saving probe parameters\n","[epoch 4] Train loss: 0.5265979903719656, Dev loss: 0.5567510291321637\n","[epoch 5] Train loss: 0.498458036571007, Dev loss: 0.5404624799417233\n","Saving probe parameters\n","[epoch 6] Train loss: 0.4925585689219039, Dev loss: 0.5397574441370602\n","Saving probe parameters\n","[epoch 7] Train loss: 0.49037764351448426, Dev loss: 0.5388629623546102\n","Saving probe parameters\n","[epoch 8] Train loss: 0.488925477197797, Dev loss: 0.5385584647153709\n","Saving probe parameters\n","[epoch 9] Train loss: 0.487833867696993, Dev loss: 0.5389168458442165\n","[epoch 10] Train loss: 0.4837696657767433, Dev loss: 0.5380843252797204\n","Saving probe parameters\n","[epoch 11] Train loss: 0.4833762757892825, Dev loss: 0.5379885985872072\n","[epoch 12] Train loss: 0.48317199136790434, Dev loss: 0.5380207681715266\n","[epoch 13] Train loss: 0.4826438717653803, Dev loss: 0.5379353864106858\n","Saving probe parameters\n","[epoch 14] Train loss: 0.4825725774014305, Dev loss: 0.5379309995682123\n","[epoch 15] Train loss: 0.4825696201783092, Dev loss: 0.537927111831133\n","[epoch 16] Train loss: 0.48256687586332075, Dev loss: 0.5379238277117016\n","[epoch 17] Train loss: 0.48256436897259436, Dev loss: 0.5379212377674107\n","[epoch 18] Train loss: 0.48256198075515855, Dev loss: 0.537918848534153\n","Early stopping\n","[training]:  60% 18/30 [01:22<00:55,  4.59s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 630.35it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-distance-10\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 10\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:55<00:00, 276.28it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 10\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 289.81it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 10\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 283.39it/s]\n","[computing labels]: 100% 15346/15346 [03:32<00:00, 72.19it/s]\n","[computing labels]: 100% 803/803 [00:09<00:00, 82.47it/s]\n","[computing labels]: 100% 1905/1905 [00:23<00:00, 80.29it/s] \n","Constructing TwoWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.5926220324737657, Dev loss: 1.3339174491530783\n","Saving probe parameters\n","[epoch 1] Train loss: 0.9977846528752662, Dev loss: 1.0010751757497063\n","Saving probe parameters\n","[epoch 2] Train loss: 1.020111852964304, Dev loss: 1.0875257448122777\n","[epoch 3] Train loss: 0.8101622020500697, Dev loss: 0.7803563261091486\n","Saving probe parameters\n","[epoch 4] Train loss: 0.7707567615489147, Dev loss: 0.7756444058412336\n","Saving probe parameters\n","[epoch 5] Train loss: 0.7616422087804724, Dev loss: 0.7732630205035655\n","Saving probe parameters\n","[epoch 6] Train loss: 0.7577882283951645, Dev loss: 0.7729716669132523\n","Saving probe parameters\n","[epoch 7] Train loss: 0.755560518367558, Dev loss: 0.7714030430889961\n","Saving probe parameters\n","[epoch 8] Train loss: 0.7542587808131488, Dev loss: 0.7708362190987669\n","Saving probe parameters\n","[epoch 9] Train loss: 0.7531163736441822, Dev loss: 0.7693432357213269\n","Saving probe parameters\n","[epoch 10] Train loss: 0.7525850859767188, Dev loss: 0.7692177567357292\n","Saving probe parameters\n","[epoch 11] Train loss: 0.7524284703874781, Dev loss: 0.7695821923010079\n","[epoch 12] Train loss: 0.7297027993975912, Dev loss: 0.7588858990413908\n","Saving probe parameters\n","[epoch 13] Train loss: 0.7247488641776179, Dev loss: 0.7575406796608589\n","Saving probe parameters\n","[epoch 14] Train loss: 0.7233086492874531, Dev loss: 0.7566231377840339\n","Saving probe parameters\n","[epoch 15] Train loss: 0.7225386187537124, Dev loss: 0.7564912587589819\n","Saving probe parameters\n","[epoch 16] Train loss: 0.7220590180000923, Dev loss: 0.7560365538519911\n","Saving probe parameters\n","[epoch 17] Train loss: 0.7218018545098307, Dev loss: 0.7568326118131948\n","[epoch 18] Train loss: 0.7183660657654743, Dev loss: 0.7560599224356608\n","[epoch 19] Train loss: 0.7178287695955923, Dev loss: 0.7559987183377277\n","[epoch 20] Train loss: 0.7177702414077496, Dev loss: 0.7559940874353887\n","[epoch 21] Train loss: 0.7177676541171701, Dev loss: 0.7559913389412581\n","Early stopping\n","[training]:  70% 21/30 [02:20<01:00,  6.70s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 480.37it/s]\n","Reporting spearmanr on split dev\n","Reporting uuas on split dev\n","[uuas,tikz]: 81it [00:21,  3.71it/s]\n","Constructing new results directory at results/parse-depth-10\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 10\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:51<00:00, 299.49it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 10\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 373.16it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 10\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:05<00:00, 367.66it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2595.75it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2874.73it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2751.85it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.4979685171321957, Dev loss: 0.8349974176209712\n","Saving probe parameters\n","[epoch 1] Train loss: 0.8507180160794406, Dev loss: 0.8051241518996869\n","Saving probe parameters\n","[epoch 2] Train loss: 0.8377486433026441, Dev loss: 1.038547429765295\n","[epoch 3] Train loss: 0.5895841535091959, Dev loss: 0.5781915692582373\n","Saving probe parameters\n","[epoch 4] Train loss: 0.5532100927902762, Dev loss: 0.5741047244588584\n","Saving probe parameters\n","[epoch 5] Train loss: 0.5440793827896585, Dev loss: 0.5757114435934635\n","[epoch 6] Train loss: 0.5157417643882765, Dev loss: 0.558807260814966\n","Saving probe parameters\n","[epoch 7] Train loss: 0.509874367129767, Dev loss: 0.557806113588706\n","Saving probe parameters\n","[epoch 8] Train loss: 0.507726399494277, Dev loss: 0.5567799891214145\n","Saving probe parameters\n","[epoch 9] Train loss: 0.5062154125051798, Dev loss: 0.558058160625092\n","[epoch 10] Train loss: 0.5022520174278549, Dev loss: 0.5563787253084099\n","Saving probe parameters\n","[epoch 11] Train loss: 0.5017478730149395, Dev loss: 0.5562421945973322\n","Saving probe parameters\n","[epoch 12] Train loss: 0.5015559880841932, Dev loss: 0.556258895477352\n","[epoch 13] Train loss: 0.5010321012115627, Dev loss: 0.5562082851215139\n","[epoch 14] Train loss: 0.5009613506302721, Dev loss: 0.5562016494841238\n","[epoch 15] Train loss: 0.5009581785103837, Dev loss: 0.5561996777060617\n","[epoch 16] Train loss: 0.5009553344840412, Dev loss: 0.5561981679196673\n","Early stopping\n","[training]:  53% 16/30 [01:13<01:04,  4.61s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 633.50it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-distance-11\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 11\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:55<00:00, 278.33it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 11\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 295.37it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 11\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 281.55it/s]\n","[computing labels]: 100% 15346/15346 [03:32<00:00, 72.29it/s]\n","[computing labels]: 100% 803/803 [00:09<00:00, 82.13it/s]\n","[computing labels]: 100% 1905/1905 [00:23<00:00, 80.02it/s] \n","Constructing TwoWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.5956935662886442, Dev loss: 0.9668492427650157\n","Saving probe parameters\n","[epoch 1] Train loss: 1.0103083310623795, Dev loss: 1.0099908898806067\n","[epoch 2] Train loss: 0.8414913879353765, Dev loss: 0.810401654629452\n","Saving probe parameters\n","[epoch 3] Train loss: 0.803149725209155, Dev loss: 0.8038447272881476\n","Saving probe parameters\n","[epoch 4] Train loss: 0.7941082172997846, Dev loss: 0.8008056458916195\n","Saving probe parameters\n","[epoch 5] Train loss: 0.7905428028317982, Dev loss: 0.8050449345803646\n","[epoch 6] Train loss: 0.7660999910377484, Dev loss: 0.7898711089327801\n","Saving probe parameters\n","[epoch 7] Train loss: 0.7614301547037177, Dev loss: 0.7883687347433487\n","Saving probe parameters\n","[epoch 8] Train loss: 0.7598073888319063, Dev loss: 0.7883914660101068\n","[epoch 9] Train loss: 0.7559403489469689, Dev loss: 0.7877012409575997\n","Saving probe parameters\n","[epoch 10] Train loss: 0.7556353400090084, Dev loss: 0.7876688584889451\n","[epoch 11] Train loss: 0.7551347373999441, Dev loss: 0.7876233597324319\n","[epoch 12] Train loss: 0.7550819119309627, Dev loss: 0.7876196171842507\n","[epoch 13] Train loss: 0.7550799172999385, Dev loss: 0.7876179227199531\n","[epoch 14] Train loss: 0.7550780679790259, Dev loss: 0.7876164435152693\n","Early stopping\n","[training]:  47% 14/30 [01:36<01:49,  6.87s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 478.03it/s]\n","Reporting spearmanr on split dev\n","Reporting uuas on split dev\n","[uuas,tikz]: 81it [00:21,  3.72it/s]\n","Constructing new results directory at results/parse-depth-11\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 11\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:47<00:00, 324.95it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 11\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 352.70it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 11\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:05<00:00, 365.21it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2606.25it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2850.26it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2714.58it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: 1.5882276811640748, Dev loss: 0.834726768294129\n","Saving probe parameters\n","[epoch 1] Train loss: 0.7988670257581783, Dev loss: 0.8657000548812848\n","[epoch 2] Train loss: 0.6098424139380781, Dev loss: 0.5990514283162423\n","Saving probe parameters\n","[epoch 3] Train loss: 0.5713155234044897, Dev loss: 0.594179255876268\n","Saving probe parameters\n","[epoch 4] Train loss: 0.5610435429723076, Dev loss: 0.5938299880971944\n","Saving probe parameters\n","[epoch 5] Train loss: 0.555652680692843, Dev loss: 0.5906034080058818\n","Saving probe parameters\n","[epoch 6] Train loss: 0.5515013434780354, Dev loss: 0.590645007445833\n","[epoch 7] Train loss: 0.5250076853776869, Dev loss: 0.5743345457174412\n","Saving probe parameters\n","[epoch 8] Train loss: 0.519482593966419, Dev loss: 0.5745812356100878\n","[epoch 9] Train loss: 0.5145889979118508, Dev loss: 0.5735761326544014\n","Saving probe parameters\n","[epoch 10] Train loss: 0.5141013574991732, Dev loss: 0.5733838728623254\n","Saving probe parameters\n","[epoch 11] Train loss: 0.5138478356950149, Dev loss: 0.5734065080787593\n","[epoch 12] Train loss: 0.5133085301502516, Dev loss: 0.5733711517614267\n","[epoch 13] Train loss: 0.5132299064424689, Dev loss: 0.5733703337748944\n","[epoch 14] Train loss: 0.5132259045028786, Dev loss: 0.5733710484368121\n","[epoch 15] Train loss: 0.5132220279404506, Dev loss: 0.5733714789560397\n","Early stopping\n","[training]:  50% 15/30 [01:09<01:09,  4.66s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 622.82it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n"]}]},{"cell_type":"markdown","source":["# Step 5. Run demo"],"metadata":{"id":"5aJs1SFMtuP8"}},{"cell_type":"markdown","source":["`bash scripts/seg.sh CONFIG.JSON_OF_YOUR_4-1_SUMISSION MY_CWS_BERT.PT_OF_YOUR_4-1_SUMISSION`\n","\n","Put the transformer directory containing your modeling_bert.py used in cws of 4-1 to assist segmentation. Finally, you will have your .tikz in seg_results/"],"metadata":{"id":"F2RczWOGtxJJ"}},{"cell_type":"code","source":["os.makedirs('data', exist_ok=True)"],"metadata":{"id":"1feAK0lmhY7u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!bash ./scripts/seg.sh ../4-1/4-1-2/output/config.json ../4-1/4-1-2/output/pytorch_model.bin"],"metadata":{"id":"7FyZmWFituBl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658848310161,"user_tz":-480,"elapsed":21650,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"63be6371-2970-4330-b3bf-b099ccaf2b8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.24.3) or chardet (2.1.1) doesn't match a supported version!\n","  RequestsDependencyWarning)\n","現在 防控 還 不 能 麻痹 ， 還是 不 要 進行 過 多 的 聚集 活動 。 \n","\n","希望 同 各 方 一道 ， 繪製 「 精甚 」 細膩 的 工筆畫 \n","\n","不 要 搞 奇奇怪怪 的 建築 。 \n","\n","沒有 可以 奉為 金科律玉 的 教科書 ， 也 沒有 可以 對 人民 頤使氣指 的 教師爺 。 \n","\n","天行健 ， 君子 以 不 強 自 … … 自強不息 。 \n","\n","我 背 過 《 新華 字典 》 \n","\n","三 隻 手 合力 。 \n","\n","在 人民 面前 ， 我們 永遠 是 小學生 。 \n","\n","別看 你 今天 鬧 得 歡 ， 小心 今後 拉 清單 ， 這 都 得 應驗 的 。 \n","\n","不 要 幹 這 種 事情 。 頭 上 三 尺 有 神明 ， 一定 要 有 敬畏 之 心 。 \n","\n","/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.24.3) or chardet (2.1.1) doesn't match a supported version!\n","  RequestsDependencyWarning)\n","Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Constructing TwoWordPSDProbe\n","Constructing OneWordPSDProbe\n","[demoing]: 10it [00:00, 10.65it/s]\n"]}]},{"cell_type":"markdown","source":["# Step 6. Plot graphs"],"metadata":{"id":"KPZzObXSvbTz"}},{"cell_type":"markdown","source":["Plot several dependency graphs given examples from dev set. The tikz file for visualization can be found after training at `results/[checkpoint_name]/dev.tikz`. You can use online service like Overleaf to complile the tikz file. An example could be found here: https://www.overleaf.com/read/bqcszyjrgnby."],"metadata":{"id":"rXPlJ4iLveeQ"}},{"cell_type":"markdown","source":["# Step 7. Bonus task"],"metadata":{"id":"GZjTMubcvoY4"}},{"cell_type":"markdown","source":["For bonus task (learning to rank instead of directly regressing), complete the TODO loss function in structural-probes/loss.py. Instead of using squared Euclidean distance as in the paper, you can also take just the Euclidean distance and perform rank loss on it by adding a probe class taking the square root of the inner product in structural-probes/probe.py, and register the probe at structural-probes/run_experiment.py."],"metadata":{"id":"PdzR2aoJvzl2"}},{"cell_type":"markdown","source":["# Report"],"metadata":{"id":"USKqGhxR_ien"}},{"cell_type":"markdown","source":["## 1"],"metadata":{"id":"mCxBUS8ERZHj"}},{"cell_type":"markdown","source":["使用 part 1 (Definition 1) 的作法，對 bert 的每一層的 embedding 去做語法樹的訓練，(每一層的 projection B matrix 都是不一樣的) ，並且繪製每一層dev的 UUAS 和 Spearman-r （一種數值一張圖）\n"],"metadata":{"id":"vXOajnCH6Qpb"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"NScvW321my9o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def draw_result(result, title, ylabel, color):\n","  plt.title(title)\n","  plt.xlabel('layer')\n","  plt.ylabel(ylabel)\n","  plt.axis([0, 13, 0, 1])\n","  plt.grid(axis='y')\n","  plt.xticks(np.arange(1, 13, step=1))\n","  plt.plot(range(1, 13), [y for y in result], 'o-', color=color)\n","  plt.show()"],"metadata":{"id":"Je8BEt8ooPvp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["uuas = []\n","spearman_r = []\n","\n","for layer in range(12):\n","  path = f'results/parse-distance-{layer}'\n","  with open(os.path.join(path, 'dev.uuas'), 'r') as f:\n","    uuas.append(float(f.readline()))\n","  with open(os.path.join(path, 'dev.spearmanr'), 'r') as f:\n","    lines = f.readlines()\n","    spearmanrs = [float(l.split('\\n')[0].split('\\t')[1]) for l in lines if 'nan' not in l]\n","    spearman_r.append(np.mean(spearmanrs))"],"metadata":{"id":"68WDYBPv6-65"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["draw_result(uuas, 'UUAS of distance probes', 'uuas', color='blue')\n","draw_result(spearman_r, 'Average speaerman-r of distance probes', 'spearman-r', color='red')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"id":"tnKzWIIZorcQ","executionInfo":{"status":"ok","timestamp":1658851079503,"user_tz":-480,"elapsed":1007,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"b7fb5b2a-7b0e-4a82-faff-5befeaeb8bb9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## 2"],"metadata":{"id":"3mbQnJz4RdWU"}},{"cell_type":"markdown","source":["使用 part 2 (Definition 2) 的作法，對 bert 的每一層的 embedding 去做語法樹的訓練，(每一層的 projection B matrix 都是不一樣的) ，訓練完之後，繪製每一層dev的 root acc 和 Spearman-r （一種數值一張圖）。\n"],"metadata":{"id":"FWGpnCbN6asu"}},{"cell_type":"code","source":["root_acc = []\n","spearman_r = []\n","\n","for layer in range(12):\n","  path = f'results/parse-depth-{layer}'\n","  with open(os.path.join(path, 'dev.root_acc'), 'r') as f:\n","    root_acc.append(float(f.readline().split('\\t')[0]))\n","  with open(os.path.join(path, 'dev.spearmanr'), 'r') as f:\n","    lines = f.readlines()\n","    spearmanrs = [float(l.split('\\n')[0].split('\\t')[1]) for l in lines if 'nan' not in l]\n","    spearman_r.append(np.mean(spearmanrs))"],"metadata":{"id":"feXfHFO25GCc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["draw_result(root_acc, 'Root-acc of depth probes', 'root-acc', color='blue')\n","draw_result(spearman_r, 'Average speaerman-r of depth probes', 'spearman-r', color='red')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"id":"EFDkVS8x5xNY","executionInfo":{"status":"ok","timestamp":1658851115634,"user_tz":-480,"elapsed":662,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"11b8e209-1c42-4c97-aee4-c8110ce131ee"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## 3"],"metadata":{"id":"DTpLpZpFRfBw"}},{"cell_type":"markdown","source":["對第一種方法而言，我們可以用每個word pair之間的距離建成一個minimum spanning tree （類似於語法樹）。拿第一題中uuas最高的layer的probe對下列十句句子投影、計算每個word之間的距離，並依算出來的結果繪製出 minimum spanning tree。所有code都在github上，但visualization須將code產生的.tikz檔傳到overleaf上。\n","\n","1. 現在防控還不能麻痹，還是不要進行過多的聚集活動。\n","2. 希望同各方一道，繪製「精甚」細膩的工筆畫\n","3. 不要搞奇奇怪怪的建築。\n","4. 沒有可以奉為金科律玉的教科書，也沒有可以對人民頤使氣指的教師爺。\n","5. 天行健，君子以不強自……自強不息。\n","6. 我背過《新華字典》\n","7. 三隻手合力。\n","8. 在人民面前，我們永遠是小學生。\n","9. 別看你今天鬧得歡，小心今後拉清單，這都得應驗的。\n","10. 不要幹這種事情。頭上三尺有神明，一定要有敬畏之心\n"],"metadata":{"id":"DW4jBZhp6pKN"}},{"cell_type":"markdown","source":["https://www.overleaf.com/read/yjydwshxhvxt"],"metadata":{"id":"OZU7_du6SAPo"}},{"cell_type":"markdown","source":["## Bonus"],"metadata":{"id":"kEe581y0Rl3X"}},{"cell_type":"markdown","source":["Redo problem 2 with rank loss"],"metadata":{"id":"CgRgFItq67L5"}},{"cell_type":"code","source":["for layer in range(12): \n","  !python structural-probes/experiment_yaml.py --model_layer $layer --task_name 'parse-depth-rankloss' \n","  !python structural-probes/run_experiment.py example/config/ctb/pad_ctb-BERTbase.yaml"],"metadata":{"id":"VzKxWlpD669j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658848149526,"user_tz":-480,"elapsed":1329708,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"20ab888d-3704-42a9-e348-77abd1d105d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Constructing new results directory at results/parse-depth-rankloss-0\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 0\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [01:00<00:00, 252.02it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 0\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:03<00:00, 254.04it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 0\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:07<00:00, 238.81it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2649.72it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2900.24it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2752.44it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: -0.0669549219645283, Dev loss: 0.0\n","Saving probe parameters\n","[epoch 1] Train loss: 0.0, Dev loss: 0.0\n","[epoch 2] Train loss: 0.0, Dev loss: 0.0\n","[epoch 3] Train loss: 0.0, Dev loss: 0.0\n","[epoch 4] Train loss: 0.0, Dev loss: 0.0\n","[epoch 5] Train loss: 0.0, Dev loss: 0.0\n","Early stopping\n","[training]:  17% 5/30 [00:31<02:36,  6.26s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 620.33it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-depth-rankloss-1\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 1\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [01:03<00:00, 240.95it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 1\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:03<00:00, 243.73it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 1\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:07<00:00, 250.90it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2673.00it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2954.48it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2826.18it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: -18.327768031860693, Dev loss: 0.0\n","Saving probe parameters\n","[epoch 1] Train loss: 0.0, Dev loss: 0.0\n","[epoch 2] Train loss: 0.0, Dev loss: 0.0\n","[epoch 3] Train loss: 0.0, Dev loss: 0.0\n","[epoch 4] Train loss: 0.0, Dev loss: 0.0\n","[epoch 5] Train loss: 0.0, Dev loss: 0.0\n","Early stopping\n","[training]:  17% 5/30 [00:31<02:35,  6.22s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 631.47it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-depth-rankloss-2\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 2\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:58<00:00, 260.15it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 2\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 283.84it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 2\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 280.52it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2687.86it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 3001.17it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2865.78it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: -0.1789429178142212, Dev loss: 0.0\n","Saving probe parameters\n","[epoch 1] Train loss: 0.0, Dev loss: 0.0\n","[epoch 2] Train loss: 0.0, Dev loss: 0.0\n","[epoch 3] Train loss: 0.0, Dev loss: 0.0\n","[epoch 4] Train loss: 0.0, Dev loss: 0.0\n","[epoch 5] Train loss: 0.0, Dev loss: 0.0\n","Early stopping\n","[training]:  17% 5/30 [00:30<02:34,  6.20s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 621.77it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-depth-rankloss-3\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 3\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:55<00:00, 277.25it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 3\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 298.52it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 3\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 299.45it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2663.99it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2884.78it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2833.86it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: -1.0615537752931778, Dev loss: 0.0\n","Saving probe parameters\n","[epoch 1] Train loss: 0.0, Dev loss: 0.0\n","[epoch 2] Train loss: 0.0, Dev loss: 0.0\n","[epoch 3] Train loss: 0.0, Dev loss: 0.0\n","[epoch 4] Train loss: 0.0, Dev loss: 0.0\n","[epoch 5] Train loss: 0.0, Dev loss: 0.0\n","Early stopping\n","[training]:  17% 5/30 [00:31<02:35,  6.24s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 616.86it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-depth-rankloss-4\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 4\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:52<00:00, 290.48it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 4\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 306.85it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 4\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 296.93it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2650.17it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2916.46it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2753.83it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: -10.587707382750514, Dev loss: 0.0\n","Saving probe parameters\n","[epoch 1] Train loss: 0.0, Dev loss: 0.0\n","[epoch 2] Train loss: 0.0, Dev loss: 0.0\n","[epoch 3] Train loss: 0.0, Dev loss: 0.0\n","[epoch 4] Train loss: 0.0, Dev loss: 0.0\n","[epoch 5] Train loss: 0.0, Dev loss: 0.0\n","Early stopping\n","[training]:  17% 5/30 [00:31<02:35,  6.22s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 632.23it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-depth-rankloss-5\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 5\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:56<00:00, 273.76it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 5\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 289.90it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 5\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 282.23it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2617.63it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2883.56it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2811.09it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: -0.07788221897924177, Dev loss: 0.0\n","Saving probe parameters\n","[epoch 1] Train loss: 0.0, Dev loss: 0.0\n","[epoch 2] Train loss: 0.0, Dev loss: 0.0\n","[epoch 3] Train loss: 0.0, Dev loss: 0.0\n","[epoch 4] Train loss: 0.0, Dev loss: 0.0\n","[epoch 5] Train loss: 0.0, Dev loss: 0.0\n","Early stopping\n","[training]:  17% 5/30 [00:31<02:36,  6.24s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 620.81it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-depth-rankloss-6\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 6\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:54<00:00, 282.05it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 6\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 301.87it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 6\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 296.13it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2645.87it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2899.27it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2800.81it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: -2.0929452698373368, Dev loss: 0.0\n","Saving probe parameters\n","[epoch 1] Train loss: 0.0, Dev loss: 0.0\n","[epoch 2] Train loss: 0.0, Dev loss: 0.0\n","[epoch 3] Train loss: 0.0, Dev loss: 0.0\n","[epoch 4] Train loss: 0.0, Dev loss: 0.0\n","[epoch 5] Train loss: 0.0, Dev loss: 0.0\n","Early stopping\n","[training]:  17% 5/30 [00:31<02:36,  6.27s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 622.33it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-depth-rankloss-7\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 7\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:51<00:00, 295.60it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 7\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 321.88it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 7\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 313.32it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2640.35it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2927.01it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2793.35it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: -0.06940829140195694, Dev loss: 0.0\n","Saving probe parameters\n","[epoch 1] Train loss: 0.0, Dev loss: 0.0\n","[epoch 2] Train loss: 0.0, Dev loss: 0.0\n","[epoch 3] Train loss: 0.0, Dev loss: 0.0\n","[epoch 4] Train loss: 0.0, Dev loss: 0.0\n","[epoch 5] Train loss: 0.0, Dev loss: 0.0\n","Early stopping\n","[training]:  17% 5/30 [00:31<02:36,  6.26s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 616.61it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-depth-rankloss-8\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 8\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:52<00:00, 294.31it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 8\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 325.21it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 8\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 312.88it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2640.68it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2894.35it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2771.01it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: -0.031850274905191475, Dev loss: 0.0\n","Saving probe parameters\n","[epoch 1] Train loss: 0.0, Dev loss: 0.0\n","[epoch 2] Train loss: 0.0, Dev loss: 0.0\n","[epoch 3] Train loss: 0.0, Dev loss: 0.0\n","[epoch 4] Train loss: 0.0, Dev loss: 0.0\n","[epoch 5] Train loss: 0.0, Dev loss: 0.0\n","Early stopping\n","[training]:  17% 5/30 [00:31<02:35,  6.22s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 624.20it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-depth-rankloss-9\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 9\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:51<00:00, 297.72it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 9\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 310.73it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 9\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 303.26it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2659.50it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2881.71it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2803.72it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: -0.010769781786072104, Dev loss: 0.0\n","Saving probe parameters\n","[epoch 1] Train loss: 0.0, Dev loss: 0.0\n","[epoch 2] Train loss: 0.0, Dev loss: 0.0\n","[epoch 3] Train loss: 0.0, Dev loss: 0.0\n","[epoch 4] Train loss: 0.0, Dev loss: 0.0\n","[epoch 5] Train loss: 0.0, Dev loss: 0.0\n","Early stopping\n","[training]:  17% 5/30 [00:31<02:36,  6.27s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 625.38it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-depth-rankloss-10\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 10\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:50<00:00, 301.29it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 10\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 326.64it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 10\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 316.32it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2685.78it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 3006.40it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2846.96it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: -0.8700545273811522, Dev loss: 0.0\n","Saving probe parameters\n","[epoch 1] Train loss: 0.0, Dev loss: 0.0\n","[epoch 2] Train loss: 0.0, Dev loss: 0.0\n","[epoch 3] Train loss: 0.0, Dev loss: 0.0\n","[epoch 4] Train loss: 0.0, Dev loss: 0.0\n","[epoch 5] Train loss: 0.0, Dev loss: 0.0\n","Early stopping\n","[training]:  17% 5/30 [00:30<02:34,  6.19s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 630.64it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n","Constructing new results directory at results/parse-depth-rankloss-11\n","Loading BERT Pretrained Embeddings from /content/ctb/train.bertbase-layers.hdf5; using layer 11\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]:   0% 0/15346 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:402: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  single_layer_features = torch.tensor([np.mean(single_layer_features[untok_tok_mapping[i][0]:untok_tok_mapping[i][-1]+1,:], axis=0) for i in range(len(untokenized_sent))])\n","[aligning embeddings]: 100% 15346/15346 [00:50<00:00, 303.05it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/dev.bertbase-layers.hdf5; using layer 11\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 803/803 [00:02<00:00, 318.34it/s]\n","Loading BERT Pretrained Embeddings from /content/ctb/test.bertbase-layers.hdf5; using layer 11\n","Using BERT-base-chinese tokenizer to align embeddings with CTB tokens\n","[aligning embeddings]: 100% 1905/1905 [00:06<00:00, 297.70it/s]\n","[computing labels]: 100% 15346/15346 [00:05<00:00, 2662.87it/s]\n","[computing labels]: 100% 803/803 [00:00<00:00, 2956.54it/s]\n","[computing labels]: 100% 1905/1905 [00:00<00:00, 2793.96it/s]\n","Constructing OneWordPSDProbe\n","Training probe...\n","[training]:   0% 0/30 [00:00<?, ?it/s]/content/drive/MyDrive/Colab Notebooks/NTU_Deep Learning for Human Language Processing_Spring2020/HW4/4-2/structural-probes/data.py:257: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  seqs = [torch.tensor(x[0].embeddings, device=self.args['device']) for x in batch_observations]\n","[epoch 0] Train loss: -6.0007647151790415, Dev loss: 0.0\n","Saving probe parameters\n","[epoch 1] Train loss: 0.0, Dev loss: 0.0\n","[epoch 2] Train loss: 0.0, Dev loss: 0.0\n","[epoch 3] Train loss: 0.0, Dev loss: 0.0\n","[epoch 4] Train loss: 0.0, Dev loss: 0.0\n","[epoch 5] Train loss: 0.0, Dev loss: 0.0\n","Early stopping\n","[training]:  17% 5/30 [00:31<02:35,  6.23s/it]\n","Reporting results of trained probe...\n","[predicting]: 100% 81/81 [00:00<00:00, 608.20it/s]\n","Reporting spearmanr on split dev\n","Reporting root_acc on split dev\n"]}]},{"cell_type":"code","source":["root_acc = []\n","spearman_r = []\n","\n","for layer in range(12):\n","  path = f'results/parse-depth-rankloss-{layer}'\n","  with open(os.path.join(path, 'dev.root_acc'), 'r') as f:\n","    root_acc.append(float(f.readline().split('\\t')[0]))\n","  with open(os.path.join(path, 'dev.spearmanr'), 'r') as f:\n","    lines = f.readlines()\n","    spearmanrs = [float(l.split('\\n')[0].split('\\t')[1]) for l in lines if 'nan' not in l]\n","    spearman_r_mean = np.mean(spearmanrs) if spearmanrs else 0\n","    spearman_r.append(spearman_r_mean)"],"metadata":{"id":"04YaoiKX4FJR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["draw_result(root_acc, 'Root-acc of depth-rankloss probes', 'root-acc', color='blue')\n","draw_result(spearman_r, 'Average speaerman-r of depth-rankloss probes', 'spearman-r', color='red')"],"metadata":{"id":"wNROhybtWn02","colab":{"base_uri":"https://localhost:8080/","height":573},"executionInfo":{"status":"ok","timestamp":1658851146330,"user_tz":-480,"elapsed":744,"user":{"displayName":"gene chen","userId":"17907428316458469282"}},"outputId":"62b8ae68-d54a-49ce-b329-51b74e489cfe"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[],"metadata":{"id":"bX3ap80R9YDS"},"execution_count":null,"outputs":[]}]}